{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = './data/spam_data/train/ham/1387.2000-06-17.farmer.ham.txt'\n",
    "\n",
    "# with open(file_path, \"r\") as infile:\n",
    "#     ham_sample = infile.read()\n",
    "\n",
    "# print(ham_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = './data/spam_data/train/spam/1778.2004-08-09.GP.spam.txt'\n",
    "\n",
    "# with open(file_path, \"r\") as infile:\n",
    "#     spam_sample = infile.read()\n",
    "\n",
    "# print(spam_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Buh text file iig unshaad ham/spam gedgeer ni label uusgene\n",
    "# # spam bol 1\n",
    "# # ham bol 0\n",
    "# import os\n",
    "# import glob\n",
    "\n",
    "# mails = []\n",
    "# labels = []\n",
    "\n",
    "# # spam e-mail uudiig unshina\n",
    "# file_path = './data/spam_data/train/spam/'\n",
    "# for filename in glob.glob(os.path.join(file_path, '*.txt')):\n",
    "#     with open(filename, \"r\", encoding=\"ISO-8859-1\") as infile:\n",
    "#         mails.append(infile.read())\n",
    "#         labels.append(1) \n",
    "\n",
    "# print(\"--------------SPAM------------- \\n\", mails[0], labels[0], \"\\n--------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"./data/spam_data/train/ham/\"\n",
    "# for filename in glob.glob(os.path.join(file_path, \"*.txt\")):\n",
    "#     with open(filename, \"r\", encoding=\"ISO-8859-1\") as infile:\n",
    "#         mails.append(infile.read())\n",
    "#         labels.append(0)\n",
    "\n",
    "# print(\"--------------------HAM------------------ \\n\", mails[1], labels[1], \"\\n-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from math import *\n",
    "from pathlib import Path\n",
    "import re\n",
    "import glob\n",
    "from random import shuffle\n",
    "from collections import *\n",
    "from typing import *\n",
    "\n",
    "\n",
    "spam_data_path = './data/train_data/train/spam/'\n",
    "ham_data_path = './data/train_data/train/ham/'\n",
    "\n",
    "spam_test_path = \"./data/train_data/dev/spam\"\n",
    "ham_test_path = \"./data/train_data/dev/ham/\"\n",
    "\n",
    "class Message(NamedTuple):\n",
    "    text: str\n",
    "    is_spam: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam 1000\n",
      "ham 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_message_paths = glob.glob(str(spam_data_path + '/*.txt'))\n",
    "ham_message_paths  = glob.glob(str(ham_data_path + '/*.txt'))\n",
    "\n",
    "print(\"spam\", len(spam_message_paths))\n",
    "print(\"ham\", len(ham_message_paths))\n",
    "message_paths = ham_message_paths + spam_message_paths\n",
    "len(message_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam 26\n",
      "ham 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_message_paths_test = glob.glob(str(spam_test_path + '/*.txt'))\n",
    "ham_message_paths_test  = glob.glob(str(ham_test_path + '/*.txt'))\n",
    "\n",
    "print(\"spam\", len(spam_test_path))\n",
    "print(\"ham\", len(ham_test_path))\n",
    "test_message_pathz = spam_message_paths_test + ham_message_paths_test\n",
    "len(test_message_pathz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "for path in message_paths:\n",
    "    \n",
    "    with open(path, errors='ignore') as file:\n",
    "        # is_spam = True if \"spam\" in path else False\n",
    "        if \"spam\" in path:\n",
    "            is_spam = True\n",
    "        else: \n",
    "            is_spam = False\n",
    "    \n",
    "        text: str = file.readline().replace('Subject:', '').strip()\n",
    "        messages.append(Message(text, is_spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages = []\n",
    "\n",
    "message_paths = test_message_pathz\n",
    "for path in message_paths:\n",
    "    \n",
    "    with open(path, errors='ignore') as file:\n",
    "        # is_spam = True if \"spam\" in path else False\n",
    "        if \"spam\" in path:\n",
    "            is_spam = True\n",
    "        else: \n",
    "            is_spam = False\n",
    "          \n",
    "        # print(path, is_spam)\n",
    "        text: str = file.readline().replace('Subject:', '').strip()\n",
    "        test_messages.append(Message(text, is_spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str):\n",
    "    words = []\n",
    "    # tokenizer hiihdee regex eer haigaad \n",
    "    # olson bug ugeeree guigeed bugdeng ni lowercase bolgood\n",
    "    # words list ruu nemne\n",
    "    for word in re.findall(r'[A-Za-z0-9\\']+', text):\n",
    "        if len(word) >= 2:\n",
    "            words.append(word.lower())\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit learnii 80, 20 oor ni huvaadag code iig garaar bichiv\n",
    "# assert hiij testlev.\n",
    "\n",
    "# def train_test_split(messages: List[Message], pct=0.8) -> Tuple[List[Message], List[Message]]:\n",
    "#     shuffle(messages)\n",
    "#     num_train = int(round(len(messages) * pct, 0))\n",
    "#     return messages[:num_train], messages[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (431731492.py, line 67)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_5882/431731492.py\"\u001b[0;36m, line \u001b[0;32m67\u001b[0m\n\u001b[0;31m    text_words: = tokenize(text)\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, k=1):\n",
    "        self.k = k\n",
    "        self.num_spam_messages: int = 0\n",
    "        self.num_ham_messages: int = 0\n",
    "        self.num_word_in_spam = defaultdict(int)\n",
    "        self.num_word_in_ham = defaultdict(int)\n",
    "        self.spam_words = set()\n",
    "        self.ham_words = set()\n",
    "        self.words = set()\n",
    "\n",
    "    # train hesgiin codenii hiij bga ni \n",
    "    # label hiigdsen message uudiig avaad deegur ni iterate hiij message bolgonoor guine\n",
    "    # teriige tokenize hiij ug ug bolgono.\n",
    "    # ahiad itrate hiij guigeed constructor deer bga state uudiigee update hiine\n",
    "    def train(self, messages):\n",
    "        for msg in messages:\n",
    "            tokens = tokenize(msg.text)\n",
    "            self.words.update(tokens)\n",
    "            if msg.is_spam:\n",
    "                self.num_spam_messages += 1\n",
    "                self.spam_words.update(tokens)\n",
    "                for token in tokens:\n",
    "                    self.num_word_in_spam[token] += 1\n",
    "            else:\n",
    "                self.num_ham_messages += 1\n",
    "                self.ham_words.update(tokens)\n",
    "                for token in tokens:\n",
    "                    self.num_word_in_ham[token] += 1                \n",
    "    \n",
    "    # ugsun ug ni spam baih magadlaliig end tootsoj bna\n",
    "    \n",
    "    # hervee ugsun word ug ni spam dotor baihgui bol (P | S) = 0 buyu 0*0 bolchino\n",
    "    # eniig boliulahiin tuld k factor hereglene\n",
    "    # P (W | S) = k + (W | Spam) / (2 * k) + total_spam\n",
    "\n",
    "    # k iin tuslamjtai magadlal ni 0 bolohgui. 0 tei oiroltsoo too garna.\n",
    "\n",
    "    \n",
    "    def p_word_spam(self, word):\n",
    "        return (self.k + self.num_word_in_spam[word]) / ((2 * self.k) + self.num_spam_messages)\n",
    "    \n",
    "    def p_word_ham(self, word):\n",
    "        return (self.k + self.num_word_in_ham[word]) / ((2 * self.k) + self.num_ham_messages)\n",
    "    \n",
    "    # p\n",
    "    def predict(self, text):\n",
    "        text_words = tokenize(text)\n",
    "        log_p_spam = 0.0\n",
    "        log_p_ham = 0.0\n",
    "\n",
    "        for word in self.words:\n",
    "            p_spam = self.p_word_spam(word)\n",
    "            p_ham = self.p_word_ham(word)\n",
    "            if word in text_words:\n",
    "                log_p_spam += log(p_spam)\n",
    "                log_p_ham += log(p_ham)\n",
    "            else:\n",
    "                log_p_spam += log(1 - p_spam)\n",
    "                log_p_ham += log(1 - p_ham)\n",
    "\n",
    "        p_if_spam = exp(log_p_spam)\n",
    "        p_if_ham = exp(log_p_ham)\n",
    "        return p_if_spam / (p_if_spam + p_if_ham)\n",
    "    \n",
    "    def predict_ham(self, text):\n",
    "        text_words = tokenize(text)\n",
    "        log_p_spam = 0.0\n",
    "        log_p_ham = 0.0\n",
    "\n",
    "        for word in self.words:\n",
    "            p_spam = self.p_word_spam(word)\n",
    "            p_ham = self.p_word_ham(word)\n",
    "            if word in text_words:\n",
    "                log_p_spam += log(p_spam)\n",
    "                log_p_ham += log(p_ham)\n",
    "            else:\n",
    "                log_p_spam += log(1 - p_spam)\n",
    "                log_p_ham += log(1 - p_ham)\n",
    "\n",
    "        p_if_spam = exp(log_p_spam)\n",
    "        p_if_ham = exp(log_p_ham)\n",
    "        return p_if_ham / (p_if_spam + p_if_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting our Enron messages into a `train` and `test` set\n",
    "# train, test = train_test_split(messages)\n",
    "train = messages\n",
    "test = test_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data-nd baigaa Spam message uudiin too: 1000\n",
      "Train data-nd baigaa Ham message uudiin too: 1000\n",
      "Hamgiin ih spam gej toologdson ugnuud \n",
      ": [('you', 100), ('the', 92), ('your', 88), ('to', 86), ('for', 76), ('re', 60), ('and', 46), ('on', 46), ('in', 43), ('get', 41), ('is', 38), ('of', 36), ('this', 36), ('with', 34), ('new', 32), ('at', 32), ('online', 29), ('we', 28), ('it', 27), ('no', 27), ('software', 27), ('can', 26), ('from', 24), ('meds', 22), ('free', 22), ('want', 21), ('all', 21), ('best', 21), ('cialis', 20), ('cheap', 20), ('now', 19), ('soft', 19), ('00', 19), ('stock', 18), ('time', 17), ('here', 17), ('low', 17), ('viagra', 17), ('pharmacy', 17), ('are', 17), ('pain', 17), ('more', 16), ('off', 16), ('me', 16), ('prices', 16), ('need', 15), ('th', 15), ('hot', 14), ('office', 14), ('xp', 14)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = NaiveBayes()\n",
    "model.train(train)\n",
    "\n",
    "print(f'Train data-nd baigaa Spam message uudiin too: {model.num_spam_messages}')\n",
    "print(f'Train data-nd baigaa Ham message uudiin too: {model.num_ham_messages}')\n",
    "print(f'Hamgiin ih spam gej toologdson ugnuud \\n: {Counter(model.num_word_in_spam).most_common(50)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Message(text='stop the aging clock', is_spam=True),\n",
       " Message(text='discover you made money while you were sleeping aaer xchxa', is_spam=True),\n",
       " Message(text='onlinepharmacycheap', is_spam=True),\n",
       " Message(text='cohere handicraftsman', is_spam=True),\n",
       " Message(text='! ebay reguiar verification', is_spam=True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test datagaas spam uudiig ni yalgay\n",
    "spam_messages = [item for item in test if item.is_spam]\n",
    "spam_messages[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"get your viagr $ a today !\" spam baih magadlal.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9989053416549496"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = spam_messages[12].text\n",
    "print(f'\"{message}\" spam baih magadlal.')\n",
    "model.predict(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Message(text='re : resume attached', is_spam=False),\n",
       " Message(text='e - mail', is_spam=False),\n",
       " Message(text='get a $ 25 certificate just for responding to this e - mail', is_spam=False),\n",
       " Message(text='texas nom , lp dba garrison , ltd', is_spam=False),\n",
       " Message(text='june vacation', is_spam=False)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set ees ham oguulberuudiig avch bna\n",
    "ham_messages = [item for item in test if item.is_spam != True] \n",
    "ham_messages[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"sarco lateral and crow o ' connor meters\" spam baih magadlal.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.007030845822791404"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = ham_messages[11].text\n",
    "\n",
    "print(f'\"{text}\" spam baih magadlal.')\n",
    "model.predict(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NaiveBayes' object has no attribute 'predict_ham'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5882/3423895963.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mham_messages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_ham\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NaiveBayes' object has no attribute 'predict_ham'"
     ]
    }
   ],
   "source": [
    "message = ham_messages[11].text\n",
    "model.predict_ham(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
