{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhVs-V84C9zF"
      },
      "source": [
        "Энэ удаагийн бие даалтын ажлаар 2 давхаргат LSTM (long-short term memory) ашиглан мэдээний төрөл ангилах модел сургах болно.\n",
        "LSTM нь RNN(recurren neural network) - ын нэгэн төрөл бөгөөд, дарааллаас хамаарсан sequence - ыг хэрхэн таамаглахыг суралцах чадвартай. Уг суралцах чадварыг нь машин орчуулга, яриа танилт гэх мэт салбаруудад ашигладаг.\n",
        "Бүх төрлийн RNN нь recurrent давхрагатаа feedback loop (буцах давтамж) - тай байдаг. Тэдгээр нь тодорхой хугацааны турш мэдээллийг хадгалж өгч байдаг. Харин энгийн RNN - ын алдааны функцын градент нь хугацааны турш алга болсоор байдаг учир урт хугацааны хамааралтай асуудлыг шийдвэрлэж чаддаггүй.\n",
        "Харин LSTM нь өөртөө нэмэлтээр 'memory cell' гэх урт хугацааны турш мэдээллийг хадгалах санах ой төрлийн unit-тэй. Мөн мэдээллийг memory cell-д хэзээ оруулах, хэзээ нь мартуулахыг удирддаг хаалгануудтай байдаг. Энэ архитехтурыг ашиглан LSTM ын урт хугацааны туршид чухал мэдээллээ мартахгүй хадгалж чаддаг.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZHGCiuHHNSa",
        "outputId": "e3cb275c-2fe2-47d8-e4f0-55612c74e6ef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRbAuKkxHIyU"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import time\n",
        "import torch                                          # pytorch нь python-ы машин сургалтын library\n",
        "import torch.nn as nn                                 # pytorch - ын бүх neural network - ын эх класс\n",
        "import torch.nn.functional as F                       # nn - ын модулиуд нь layer болж ажилладаг бол functional ынх классууд нь арифметик үйлдэл хийдэг функцууд байна\n",
        "from torch.nn.utils.rnn import pack_padded_sequence   # pad хийсэн tensor ыг багцалж, lstm - д өгөхөд бэлэн болгон\n",
        "import torch.utils.data as data                       # pytorch - ын дататай харьцах классуудын эх класс\n",
        "from torch.utils.data import DataLoader               # DataLoader module\n",
        "from torch.utils.data.sampler import RandomSampler    # random өгөгдөл сонгож буцаах нэгэн төрлийн Sampler\n",
        "import pandas as pd                                   # Pandas нь өгөгдлийг DataFrame төрөлд оруулж, түүнтэй ажиллах боложмийг олгоно\n",
        "from collections import Counter                       # Их хэмжээний өгөгдөл тоолох"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn-IBhaL6AfO"
      },
      "source": [
        "## Дата бэлтгэл\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;Pytorch - ын Dataset модулийг ашиглах учир датагаа түүндээ зориулж бэлдэх хэрэгтэй. Иймээс Numpy - ын бүтэцтэй өгөгдөл биш, tensor өгөгдөл ашиглана. Tensor нь pytorch-ын олон хэмжээст өгөгдөл(нэг төрлийн) хадгалагч матриц юм. Pytorch - д 10 төрлийн, CPU болон GPU - д зориулсан tensor-ууд бий. Pytorch нь Numpy массивтай төстэй бүтэцтэй tensor-уудыг ашиглан өгөгдлөө сургалтын үед GPU рүү шийлжүүлэх боломжийг олгодог.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI-GchK46bTp"
      },
      "source": [
        "Dataset класс үүсгэх"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "houGgxYMHIyV"
      },
      "source": [
        "class ClassificationDataset(data.Dataset):\n",
        "    def __init__(self, data_path, vocab,classes):                                   # Dataset обьект анх үүсэх үед дуудагдах функц\n",
        "        self.word2id = vocab\n",
        "        self.class2id = classes\n",
        "        self.txt_seqs = pd.read_csv(data_path, encoding='utf-8', engine='python')   # өгөгдсөн байршил дахь .csv файлыг уншин, dataframe үүсгэнэ\n",
        "        self.num_class = len(self.class2id)\n",
        "        print(\"Loaded Dataset\", len(self.txt_seqs))\n",
        "\n",
        "    def __len__(self):                                                              # Dataset ын уртыг буцаана (DataLoader үүсэх үед)\n",
        "        return len(self.txt_seqs)\n",
        "\n",
        "    def __getitem__(self, index):                                                   # dataset - с өгөгсдөн index дахь датаг буцаана\n",
        "        data = self.txt_seqs.iloc[index]\n",
        "        word_id_seq = self._preprocess(data[\"news\"])\n",
        "        return word_id_seq, torch.LongTensor([self.class2id.get(data[\" label\"])])   # оролтын болон target дата хослолыг буцаана\n",
        "\n",
        "    def _preprocess(self, txt_seq):\n",
        "        return torch.LongTensor([self.word2id.get(token, self.word2id['<unk>']) for token in txt_seq.split()])  # оролтын өгөгдлийг цэвэрлэж, token (index) руу хөрвүүлэн, tensor утга болгоно "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpkR7cyV8fXJ"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;Одоо датагаа багц багцаар (batch) уншихад бэлтгэе. Датаг batch уудад хувааж, сургалтанд ашиглахад зориулсан DataLoader класс бий. DataLoader обьект (iterable) нь өгөгдсөн dataset-р гүйж давтана. Доорх BatchSampler класс нь өгөгдсөн датасетээс датаг random оор сонгож өгнө. Цаашид бид мөн сургалтын явцад validate хийх датагаа batch, batch аар нь __iter__() - р авах болно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXWkXQmRHIyV"
      },
      "source": [
        "class BatchSampler(object):\n",
        "    def __init__(self, data_source, batch_size):\n",
        "        self.sampler = RandomSampler(data_source)                   # random өгөгдөл сонгож буцаах нэгэн төрлийн Sampler\n",
        "        self.batch_size = batch_size\n",
        "        self.random_batches = self._make_batches()                  # санамсаргүйгээр өгөгдлүүдийг сонгож, batch үүсгэх\n",
        "\n",
        "    def _make_batches(self):\n",
        "        indices = [i for i in self.sampler]\n",
        "        batches = [indices[i:i + self.batch_size] for i in range(0, len(indices), self.batch_size)]\n",
        "        random_indices = torch.randperm(len(batches)).tolist()\n",
        "        return [batches[i] for i in random_indices]                 # batch буцаана\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.sampler)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch in self.random_batches:                           # санамсаргүй сонгогдсон batch уудыг нэг нэгээр нь дуудаж ашиглана\n",
        "          if len(self.random_batches) > 1:\n",
        "            yield batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_jv3KQt9Mgh"
      },
      "source": [
        "LSTM, CNN, RNN гэх мэт network - уудад адил урттай sequential оролтыг өгөх шаардлагатай байдаг. Тиймээс өөр өөр урттай оролтуудыг 'pad' хийж адил урттай болгоё.\n",
        "Ж/нь: <div>[1,2,3,4,5,6]<br>[1,2,3]<br>[1,2,3,4,5]</div>\n",
        "Гэсэн batch хэмжээ нь 3 оролтыг:\n",
        "<div>[1,2,3,4,5,6]<br>[0,0,0,1,2,3]<br>[0,1,2,3,4,5]</div>\n",
        "болгон адил урттай болгох юм.\n",
        "\n",
        "Энэ нь pre-padding гэх арга бөгөөд, post-padding - ыг ашиглаагүйн шалтгаан нь, padding нь sequence нь төгсгөлд байрлах юм бол sequence ын эхэнд байсан чухал үгүүд мартагдах болно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Nrqx0eHIyV"
      },
      "source": [
        "class Padder(object):\n",
        "    def __init__(self):pass\n",
        "    def __call__(self, batch):\n",
        "        input_seqs, label_seqs = zip(*batch)                      # Batch өгөгдлийг оролт/гаралт - аар задлав\n",
        "        lengths = [len(seq) for seq in input_seqs]                # Batch дахь оролтын өгөгдлүүдийн уртууд\n",
        "        input_padded_seqs = torch.zeros(len(input_seqs), max(lengths)).long()     # Уртуудаас хамгийн уртаар нь хоосон tensor үүсгэв.  shape = batch_size x хамгийн урт оролтын урт\n",
        "        output_padded_seqs = torch.zeros(len(input_seqs)).long()  # Мөн адил гаралтад зориулсан хоосон tensor үүсгэв. shape = batch_size\n",
        "        for i, input in enumerate(input_seqs):\n",
        "            end = lengths[i]\n",
        "            input_padded_seqs[i, (max(lengths) - end):] = input[:end]   # Дээр үүсгэсэн хоосон tensor-тоо орлтын утгуудаа төгсгөл хэсэгт нь хийв\n",
        "            output_padded_seqs[i] = label_seqs[i][0]              \n",
        "        return input_padded_seqs, torch.IntTensor(lengths), output_padded_seqs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBR3ydxGHIyV"
      },
      "source": [
        "def build_data_loader(data, vocab, classes, batch_size, num_workers):\n",
        "    dataset = ClassificationDataset(data, vocab, classes)              # Датасет обьект үүсгэв\n",
        "    batch_sampler = BatchSampler(dataset,batch_size)                   # dataset - с өгөгдлийг багцлах обьектоо үүсгэв\n",
        "    collate_fn = Padder()                                              # pre-padding обьект\n",
        "    data_loader = DataLoader(dataset, batch_sampler=batch_sampler, collate_fn=collate_fn, num_workers=num_workers) # DataLoader нь датасетээс batch-ууд үүсгэж, pad хийнэ\n",
        "    return data_loader                                                 # DataLoader нь pytorch-ын дататай харьцах зүрх нь болсон модуль юм."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y-7TiWDC2bE"
      },
      "source": [
        "## Neural network архитехтур"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfnOeVTCC7pJ"
      },
      "source": [
        "Pytorch - ын бүх neural network модулиудын эх класс нь torch.nn.Module байдаг."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmT4DyOsHIyV"
      },
      "source": [
        "class LstmClassification(nn.Module):\n",
        "    def __init__(self, num_embeddings, embedding_dim,hidden_size, num_layers,num_class, dropout, bidirectional):\n",
        "        super(LstmClassification, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)      # Embedding нь үгсийн утгыг тоон хэлбэрт хөрвүүлж, олон хэмжээст вектор болгон хадгалах үүрэгтэй.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers,batch_first=True,dropout=dropout,bidirectional=bool(bidirectional))  # 2 чиглэлт, LSTM үүсгэлт\n",
        "        fc_in_dim = hidden_size * 2 * num_layers if bidirectional else hidden_size     # BiLSTM(Bidirecional LSTM) ын гаралт нь ердийн LSTM - с 2 чиглэлтэй\n",
        "        # учир 2 дахин урт хэлбэртэй гаралт гарна, LSTM - ын дараагаар бид fully connected layer-лүү өгөгдлөө оруулах учир fc-ын оролтын хэмжээсийг тодорхойлж өгнө\n",
        "        self.linearDP = torch.nn.Dropout(dropout)    # LSTM нь сургалтын өгөгдөлд overfit (хэт итгэлтэй болох) магадлалтай тул, сургалтын явцад таамгаар оролтуудыг хасан, accuracy - г нэмэгдүүлнэ.\n",
        "        self.fc = nn.Linear(fc_in_dim, num_class)    # fully connected layer нь оролтоо дараагийн layer - т шилжүүлэхэд хэлбэржүүлж, тусална.\n",
        "        \n",
        "    def forward(self, padded_input, input_lengths):\n",
        "        padded_input = self.embedding(padded_input) # оролтын өгөгдлүүдийг embedding vector луу шилжүүлэв. shape = batch_size * max(input_lengths) * embedding_dim\n",
        "        packed_input = pack_padded_sequence(padded_input, input_lengths.cpu(),batch_first=True, enforce_sorted=False)   # lstm руу өгөгдлөө оруулахын өмнө pad хийсэн sequence - үүдээ боох буюу pack лах ёстой байдаг.\n",
        "        _, (hidden, _) = self.lstm(packed_input)   # lstm нь гаралтын утга, оролтын утгын hidden state, cell-ын state ыг буцаадаг\n",
        "        hidden = torch.reshape(hidden.permute(1, 0, 2), (hidden.shape[1], -1))  # lstm - с гарсан hidden state ын хэлбэрийг өөрчилж, fc - д өгсөнөөр тухайн batch - ыг таамгууд гарна. \n",
        "        score = self.fc(self.linearDP(hidden))   # batch ын prediction - ууд. shape = batch_size * max(input_lengths)\n",
        "        return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aEXQfWevwFx"
      },
      "source": [
        "class Solver(object):           # Solver класс нь сургалтын явцыг удирдах болно.\n",
        "    def __init__(self, data, model, criterion, optimizer, epochs, max_norm, print_freq, file_path, use_cuda,n_classes):\n",
        "        self.tr_loader = data['tr_loader']      # сургалтын dataloader\n",
        "        self.cv_loader = data['cv_loader']      # validation dataloader\n",
        "        self.model = model                      # LSTMClassification модель\n",
        "        self.criterion = criterion              # CrossEntropyLoss\n",
        "        self.optimizer = optimizer              # Adam optimizer\n",
        "        self.n_classes = n_classes              # гаралтын утгын төрлийн тоо\n",
        "\n",
        "        self.use_cuda = use_cuda                # сургалтын үед тооцоолол хийх tensor утгуудаа gpu дээр ажиллуулах үгүйг шийднэ.\n",
        "        self.epochs = epochs                    # нийт датасетийг хэдэн удаа давтаж сургахыг удирдана.\n",
        "        self.max_norm = max_norm                # gradient clip хийх хамгийн мах утга\n",
        "        self.file_path = file_path              # model хадгалах байршил\n",
        "        self.print_freq = print_freq            # хэвлэж харуулах давтамж\n",
        "        self.traini = 0                         # сургалтын явцыг бүртгэнэ\n",
        "        self.evali = 0\n",
        "        self.prev_val_loss = float(\"inf\")       # өмнөх loss ын утгыг хадгална\n",
        "        self.best_val_loss = float(\"inf\")       # хамгийн бага loss ын утгыг хадгална. Хэрэв үүнээс бага loss гарвал моделоо хадгална.\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in range(self.epochs):        # epochs дуустал давтана.\n",
        "            print(\"Training...\")\n",
        "            self.model.train()                  # dropout болон BatchNorm - ыг идэвхжүүлж, нэг ёсондоо моделоо сургалтын горимд шилжүүлнэ. \n",
        "            start = time.time()\n",
        "\n",
        "            tr_avg_loss, epoch_acc, epoch_weighted_recall = self._run_one_epoch(epoch)  # нэг epoch сургах явц буюу сургалтын датаг бүтнээр нь нэг удаа дуустал сургана.\n",
        "\n",
        "            print('-' * 85)\n",
        "            print('Train Summary | End of Epoch {0} | Time {1:.2f}s | '\n",
        "                  'Train Loss {2:.3f} | Epoch Accuracy {3:.3f} | Epoch Weighted Recall {4:.3f}'.format(\n",
        "                epoch + 1, time.time() - start, tr_avg_loss, epoch_acc, epoch_weighted_recall))             # нэг epoch - ын сургалтын үр дүн\n",
        "            print('-' * 85)\n",
        "\n",
        "\n",
        "            print('Cross validation...')\n",
        "            self.model.eval()                        #  Batchnorm болон dropout - ыг унтраан, gradient тооцох явцыг түр зур зогсоож, моделийг өөр өгөгдөл дээр туршина\n",
        "\n",
        "            val_loss, val_epoch_acc, epoch_weighted_recall = self._run_one_epoch(epoch, cross_valid_mode=True)    # validation  ын үр дүн\n",
        "\n",
        "            print('-' * 85)\n",
        "            print('Valid Summary | End of Epoch {0} | Time {1:.2f}s | '\n",
        "                  'Valid Loss {2:.3f} | Valid Epoch Accuracy {3:.3f} | Epoch weighted recall {4:.3f}'.format(\n",
        "                epoch + 1, time.time() - start, val_loss, val_epoch_acc, epoch_weighted_recall))\n",
        "            print('-' * 85)\n",
        "\n",
        "            if val_loss < self.best_val_loss:           # Хамгийн сайн моделио хадгална.\n",
        "                self.best_val_loss = val_loss\n",
        "                save_path = os.path.join(self.file_path, \"classification_epoch%d.pth.tar\" % (epoch+1))\n",
        "                torch.save(self.model.state_dict(),save_path)\n",
        "                print(\"Илүү сайн модель оллоо, хадгалж байна: %s\" % save_path)\n",
        "\n",
        "\n",
        "    def _run_one_epoch(self, epoch, cross_valid_mode=False):\n",
        "        start = time.time()\n",
        "        total_loss = 0\n",
        "\n",
        "        data_loader = self.tr_loader if not cross_valid_mode else self.cv_loader    # dataloader \n",
        "        eval_loader = self.cv_loader.__iter__()\n",
        "        cross_valid = cross_valid_mode                                               \n",
        "        epoch_accuracy = 0.0\n",
        "        epoch_weighted_recall = 0.0\n",
        "        n_iters = 0\n",
        "\n",
        "        totalL = len(data_loader)\n",
        "        for i, (data) in enumerate(data_loader):                # DataLoader - нь iterable обьект учир давталтанд энэ байдлаар ашиглахад л batch болгож, padding хийж, shuffle хийн batch batch аар нь ашиглах боломжтой болгодог\n",
        "            padded_input, input_lengths, padded_target = data\n",
        "            if (not cross_valid_mode) & (i % self.print_freq == 0):   # validate хийх үгүйг шийднэ.\n",
        "                # do eval\n",
        "                cross_valid = True\n",
        "                self.model.eval()\n",
        "\n",
        "            if self.use_cuda:         # Хэрэв gpu ашиглах боломжтой бол tensor утгуудаа gpu руу шилжүүлнэ.\n",
        "                padded_input = padded_input.cuda()\n",
        "                input_lengths = input_lengths.cuda()\n",
        "                padded_target = padded_target.cuda()\n",
        "            predictions = self.model(padded_input, input_lengths)     # сонгогдсон batch өгөгдөл - с prediction гаргана.\n",
        "            predictions = predictions.view(-1, predictions.size(-1))  \n",
        "            loss = self.criterion(predictions, padded_target)         # prediction нь target өгөгдлөөс хэр зөрснийг тооцож, параметруудыг хэр хэмжээгээр өөрчлөхийг шийднэ.\n",
        "            # print(predictions.shape,padded_target.shape)\n",
        "            accuracy = float(sum(predictions.argmax(axis=1) == padded_target)) / float(len(padded_target))      # batch өгөгдлөөс хэдийг нь зөв таасныг тооцно.\n",
        "            if use_cuda:  \n",
        "              weights = torch.tensor([1 / (float(3 * sum(padded_target == s)) + 0.000001) for s in range(n_classes)]).cuda()\n",
        "            else:\n",
        "              weights = torch.tensor([1 / (float(3 * sum(padded_target == s)) + 0.000001) for s in range(n_classes)]).cpu()\n",
        "            weighted_recall = sum((predictions.argmax(axis=1) == padded_target) * weights[padded_target])    # weight ашиглан илүү бодит recall тооцно (тухайн класст харгалзах утгуудаас хэдийг нь зөв таасныг тооцно, тооцохдоо тухайн класс batch д хэд байгаагаас нь хамааран weight зооно)\n",
        "            epoch_accuracy += accuracy\n",
        "            epoch_weighted_recall += weighted_recall\n",
        "            if not cross_valid:                   \n",
        "                self.optimizer.zero_grad()      # backpropagation хийхийн өмнө градьентуудаа тэглэнэ.\n",
        "                loss.backward()                 # моделийн бүх параметрийн алдагдлыг тооцно.\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(),self.max_norm)\n",
        "                self.optimizer.step()           # бүх параметруудаар давтан, градьент утгуудыг нь шинэчилнэ.\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if i % self.print_freq == 0:\n",
        "                print('Epoch {0} | Iter {1:.4f} | Average Loss {2:.3f} | '\n",
        "                      'Current Loss {3:.6f} | {4:.1f} ms/batch | {5:.4f} accuracy | '\n",
        "                      '{6:.3f} weighted recall | {7} class preds'.format(\n",
        "                    epoch + 1, float(i + 1) / totalL, total_loss / (i + 1),\n",
        "                    loss.item(), 1000 * (time.time() - start) / (i + 1), accuracy, weighted_recall,   # Сургалтын үед print_freq давтамжаар үзүүлэлтүүдийг хэвлэнэ.\n",
        "                    [sum(predictions.argmax(axis=1) == padded_target).item()],\n",
        "                    flush=True))\n",
        "                if not cross_valid_mode:\n",
        "                    cross_valid = False\n",
        "                    self.evali += 1\n",
        "                    self.model.train()\n",
        "            self.traini += 1\n",
        "            n_iters = i\n",
        "\n",
        "        return total_loss / totalL, epoch_accuracy / n_iters, epoch_weighted_recall / n_iters     # нэг epoch-ын үзүүлэлт\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYzFqvcOHIyV"
      },
      "source": [
        "def clean_line(line):           # тэмдэгт мөр цэвэрлэх функц\n",
        "    line = line.lower()\n",
        "    line = re.sub(\"[\\t\\n]\", \" \", line)\n",
        "    line = re.sub(\"[<>/@%$^&*\\-+()\\[\\]~\\\"\\';:“”]+\", \" $ \", line)\n",
        "    line = re.sub(\"[0-9]+[., ][0-9]+|[0-9]+\", \"#\", line)\n",
        "    line = re.sub(\"( )*([.,?!])\", \"\\g<2> \", line)\n",
        "    line = re.sub(\"( )+\", \" \", line)\n",
        "    return line"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1BhDbLcrctD-",
        "outputId": "2b2f7c3e-033d-4ae7-bac1-3beabf9cfc20"
      },
      "source": [
        "clean_line(\"ххэхэ №- хэн  -бэ  ₮:. айн ₮ 45 юу\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ххэхэ № $ хэн $ бэ ₮ $. айн ₮ # юу'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTAQ6qrl8IZM"
      },
      "source": [
        "def num_param(model):           # моделийн параметруудыг буцаана.\n",
        "    params = 0\n",
        "    for p in model.parameters():\n",
        "        tmp = 1\n",
        "        for x in p.size():\n",
        "            tmp *= x\n",
        "        params += tmp\n",
        "    return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGSOHk9LHIyV",
        "outputId": "d0057a28-92b0-4488-98dc-2d8fbe50323b"
      },
      "source": [
        "data_file = \"/content/drive/MyDrive/ML/news.csv\"\n",
        "train_path = \"/content/drive/MyDrive/ML/train.csv\"\n",
        "valid_path = \"/content/drive/MyDrive/ML/valid.csv\"\n",
        "save_path = \"/content/drive/MyDrive/ML/\"\n",
        "vocab_size = 10000                        # үгсийн сангийн хэмжээ\n",
        "extra_word_list=[\"<unk>\", \"<end>\"]        # үгсийн сангийн map - д ашиглагдана. эдгээр нь мөн sequence ын төгсгөл, үгийн санд байхгүй байгаа үгийг тэмдэглэнэ\n",
        "df = pd.read_csv(data_file, dtype={'news': str, ' label': str}, low_memory=False)    # түүхий датагаа уншина.\n",
        "df = df.sample(None, 1.0)                                                            # датагаа холино\n",
        "df = df.dropna()                                                                     # дата дахь хоосон өгөгдөлтэй мөрийг устгана\n",
        "df = df.iloc[:70000]                                                                 # эхний 70мянган сетийг авна.  \n",
        "train_data = df.iloc[:int(len(df)*0.8)]                                              # датаныхаа 80хувийг сургалтад, 20 хувийг validation д ашиглана.\n",
        "valid_data = df.iloc[int(len(df)*0.8):int(len(df)*1)]\n",
        "print(\"Train: \",len(train_data),\" Valid: \",len(valid_data))\n",
        "train_data.to_csv(train_path,index=False)                                            # хуваасан датагаа хадгална\n",
        "valid_data.to_csv(valid_path,index=False)                                                          \n",
        "print(\"Loaded file\", data_file, \"\\t#:\", len(df))\n",
        "print(\"Cleaning lines\")\n",
        "\n",
        "df[\"news\"] = df[\"news\"].apply(lambda txt: clean_line(txt))                           # мэдээтэй баганыг цэвэрлэнэ\n",
        "words = (\" \".join(df[\"news\"].to_list())).split()                                     # бүх үгийг ялгана\n",
        "vocabs = [items for items, c in Counter(words).most_common()[:vocab_size]]           # хамгийн түгээмэл vocab_size тооны үгийг авна\n",
        "classes = df[\" label\"].unique().tolist()                                             # классуудыг list хэлбэрт шилжүүлнэ\n",
        "del df\n",
        "n = len(extra_word_list)\n",
        "vocab = { word.strip(): i + n for i, word in enumerate(vocabs) }                     # хагмийн түгээмэл үгсээр {үг: id} vocab үүсгэнэ        \n",
        "class_ids = {cls: i for i, cls in enumerate(classes)}                                # класуудаар мөн {class: id} үүсгэнэ\n",
        "for i, word in enumerate(extra_word_list):\n",
        "    vocab[word] = i\n",
        "print(\"Vocab created\")\n",
        "del words,vocabs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  56000  Valid:  14000\n",
            "Loaded file /content/drive/MyDrive/ML/news.csv \t#: 70000\n",
            "Cleaning lines\n",
            "Vocab created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfeTBE0oHIyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdef908d-7863-406f-d8f9-86e7449fc51e"
      },
      "source": [
        "num_embeddings = len(vocab) + 1       # embedding хэмжээ\n",
        "embedding_dim = 256                   # embedding хэмжээс\n",
        "hidden_size = 512                     # lstm - ын hidden state - ын feature ын тоо. hidden state гэдэг нь lstm ын cell - г хэлнэ.\n",
        "num_layers = 2                        # lstm - ын recurrent давхрагын тоо\n",
        "dropout = 0.15                        # dropout хийх магадлал\n",
        "learning_rate = 0.01                  # optimizer ын learning rate нь хэр weight - ыг өөрчлөхдөө том алхам авахыг хэлнэ. \n",
        "epochs = 30                           # хэдэн удаа нийт датанд сургахыг тохирууна\n",
        "batch_size = 32                       # нэг batch - д багтах input болон target датаны тоо\n",
        "max_norm = 5                          # gradient clip хийх хамгийн мах утга\n",
        "print_freq = 5                        # үзүүлэлтүүдийг хэвлэх давтамж\n",
        "num_workers = 1                       # dataloader iterator үүсэх үед хэдэн ажиллагч процесс үүсэхийг заана\n",
        "bidirectional = True                  # LSTM хоёр чиглэлтэй үгүйг заана (2 чиглэлтэй бол BiLSTM)\n",
        "n_classes = len(class_ids)            # классын тоо\n",
        "use_cuda = torch.cuda.is_available()  # gpu руу хөрвүүлэх боломжтой бол үнэн утга авна\n",
        "print(\"use cuda: \", use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use cuda:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "id": "kW2GtgkRHIyV",
        "outputId": "a727f1a8-63b6-4d10-84b7-c5ef45cbda0a"
      },
      "source": [
        "tr_loader = build_data_loader(train_path, vocab, class_ids, batch_size, num_workers)    # сургалтын dataloader үүсгэх\n",
        "cv_loader = build_data_loader(valid_path, vocab, class_ids, batch_size, num_workers)    # cross validation dataloader\n",
        "data = {'tr_loader': tr_loader, 'cv_loader': cv_loader}     \n",
        "\n",
        "model = LstmClassification(num_embeddings, embedding_dim,hidden_size, num_layers, tr_loader.dataset.num_class, dropout, bidirectional)     # LSTM модель үүсгэх\n",
        "if use_cuda:\n",
        "  model.cuda()      # моделио gpu руу шилжүүлэх\n",
        "print(model)\n",
        "print(\"Number of parameters: %d\" % num_param(model))      # моделийн параметрүүд\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')    # алдаа тооцох criterion\n",
        "optimizier = torch.optim.Adam(model.parameters(), lr=learning_rate)                     # параметрүүдийн weight өөрчлөх optimizer\n",
        "solver = Solver(data, model, criterion, optimizier, epochs, max_norm, print_freq,save_path,use_cuda,n_classes)  # сургалтыг удирдах обьект\n",
        "solver.train()        # сураглтаа эхлүүлцгээе"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Dataset 56000\n",
            "Loaded Dataset 14000\n",
            "LstmClassification(\n",
            "  (embedding): Embedding(10003, 256)\n",
            "  (lstm): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.15, bidirectional=True)\n",
            "  (linearDP): Dropout(p=0.15, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=9, bias=True)\n",
            ")\n",
            "Number of parameters: 12032777\n",
            "Training...\n",
            "Epoch 1 | Iter 0.0000 | Average Loss 2.169 | Current Loss 2.168671 | 527.4 ms/batch | 0.1250 accuracy | 0.500 weighted recall | [4] class preds\n",
            "Epoch 1 | Iter 0.0001 | Average Loss 6.632 | Current Loss 7.184114 | 590.7 ms/batch | 0.0312 accuracy | 0.333 weighted recall | [1] class preds\n",
            "Epoch 1 | Iter 0.0002 | Average Loss 5.416 | Current Loss 2.888473 | 535.0 ms/batch | 0.0625 accuracy | 0.389 weighted recall | [2] class preds\n",
            "Epoch 1 | Iter 0.0003 | Average Loss 4.510 | Current Loss 2.350276 | 543.6 ms/batch | 0.1250 accuracy | 0.333 weighted recall | [4] class preds\n",
            "Epoch 1 | Iter 0.0004 | Average Loss 3.992 | Current Loss 2.335399 | 579.6 ms/batch | 0.0938 accuracy | 0.250 weighted recall | [3] class preds\n",
            "Epoch 1 | Iter 0.0005 | Average Loss 3.726 | Current Loss 2.621033 | 600.4 ms/batch | 0.1250 accuracy | 0.333 weighted recall | [4] class preds\n",
            "Epoch 1 | Iter 0.0006 | Average Loss 3.506 | Current Loss 2.169549 | 569.4 ms/batch | 0.3438 accuracy | 0.389 weighted recall | [11] class preds\n",
            "Epoch 1 | Iter 0.0006 | Average Loss 3.358 | Current Loss 2.313041 | 558.4 ms/batch | 0.0312 accuracy | 0.083 weighted recall | [1] class preds\n",
            "Epoch 1 | Iter 0.0007 | Average Loss 3.234 | Current Loss 2.357237 | 560.1 ms/batch | 0.1250 accuracy | 0.333 weighted recall | [4] class preds\n",
            "Epoch 1 | Iter 0.0008 | Average Loss 3.124 | Current Loss 2.346473 | 568.9 ms/batch | 0.0938 accuracy | 0.400 weighted recall | [3] class preds\n",
            "Epoch 1 | Iter 0.0009 | Average Loss 3.055 | Current Loss 2.165387 | 574.3 ms/batch | 0.2188 accuracy | 0.417 weighted recall | [7] class preds\n",
            "Epoch 1 | Iter 0.0010 | Average Loss 2.995 | Current Loss 2.280264 | 564.6 ms/batch | 0.0625 accuracy | 0.381 weighted recall | [2] class preds\n",
            "Epoch 1 | Iter 0.0011 | Average Loss 2.934 | Current Loss 2.520801 | 571.4 ms/batch | 0.1250 accuracy | 0.370 weighted recall | [4] class preds\n",
            "Epoch 1 | Iter 0.0012 | Average Loss 2.882 | Current Loss 2.392195 | 563.6 ms/batch | 0.1250 accuracy | 0.333 weighted recall | [4] class preds\n",
            "Epoch 1 | Iter 0.0013 | Average Loss 2.839 | Current Loss 2.122480 | 572.3 ms/batch | 0.1250 accuracy | 0.298 weighted recall | [4] class preds\n",
            "Epoch 1 | Iter 0.0014 | Average Loss 2.808 | Current Loss 2.252772 | 577.8 ms/batch | 0.0625 accuracy | 0.381 weighted recall | [2] class preds\n",
            "Epoch 1 | Iter 0.0014 | Average Loss 2.779 | Current Loss 2.582282 | 579.4 ms/batch | 0.1875 accuracy | 0.381 weighted recall | [6] class preds\n",
            "Epoch 1 | Iter 0.0015 | Average Loss 2.749 | Current Loss 2.175575 | 582.3 ms/batch | 0.1250 accuracy | 0.333 weighted recall | [4] class preds\n",
            "Epoch 1 | Iter 0.0016 | Average Loss 2.726 | Current Loss 2.600718 | 582.0 ms/batch | 0.0938 accuracy | 0.375 weighted recall | [3] class preds\n",
            "Epoch 1 | Iter 0.0017 | Average Loss 2.703 | Current Loss 2.154053 | 582.0 ms/batch | 0.1875 accuracy | 0.444 weighted recall | [6] class preds\n",
            "Epoch 1 | Iter 0.0018 | Average Loss 2.685 | Current Loss 2.219157 | 583.9 ms/batch | 0.0938 accuracy | 0.417 weighted recall | [3] class preds\n",
            "Epoch 1 | Iter 0.0019 | Average Loss 2.667 | Current Loss 2.123653 | 589.9 ms/batch | 0.1875 accuracy | 0.333 weighted recall | [6] class preds\n",
            "Epoch 1 | Iter 0.0020 | Average Loss 2.649 | Current Loss 2.203891 | 590.8 ms/batch | 0.2188 accuracy | 0.333 weighted recall | [7] class preds\n",
            "Epoch 1 | Iter 0.0021 | Average Loss 2.637 | Current Loss 2.394237 | 597.0 ms/batch | 0.0938 accuracy | 0.333 weighted recall | [3] class preds\n",
            "Epoch 1 | Iter 0.0022 | Average Loss 2.625 | Current Loss 2.242068 | 590.5 ms/batch | 0.1562 accuracy | 0.333 weighted recall | [5] class preds\n",
            "Epoch 1 | Iter 0.0022 | Average Loss 2.606 | Current Loss 1.910523 | 604.7 ms/batch | 0.3750 accuracy | 0.333 weighted recall | [12] class preds\n",
            "Epoch 1 | Iter 0.0023 | Average Loss 2.593 | Current Loss 2.123328 | 603.2 ms/batch | 0.2500 accuracy | 0.381 weighted recall | [8] class preds\n",
            "Epoch 1 | Iter 0.0024 | Average Loss 2.581 | Current Loss 2.076550 | 609.1 ms/batch | 0.2812 accuracy | 0.492 weighted recall | [9] class preds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f0d8086da56f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moptimizier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m                     \u001b[0;31m# параметрүүдийн weight өөрчлөх optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# сургалтыг удирдах обьект\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# сураглтаа эхлүүлцгээе\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-541d383677e2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtr_avg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_weighted_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# нэг epoch сургах явц буюу сургалтын датаг бүтнээр нь нэг удаа дуустал сургана.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m85\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-541d383677e2>\u001b[0m in \u001b[0;36m_run_one_epoch\u001b[0;34m(self, epoch, cross_valid_mode)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0minput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mpadded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadded_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# сонгогдсон batch өгөгдөл - с prediction гаргана.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_target\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# prediction нь target өгөгдлөөс хэр зөрснийг тооцож, параметруудыг хэр хэмжээгээр өөрчлөхийг шийднэ.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-2354d9850906>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, padded_input, input_lengths)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpadded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_input\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# оролтын өгөгдлүүдийг embedding vector луу шилжүүлэв. shape = batch_size * max(input_lengths) * embedding_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpacked_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# lstm руу өгөгдлөө оруулахын өмнө pad хийсэн sequence - үүдээ боох буюу pack лах ёстой байдаг.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_input\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# lstm нь гаралтын утга, оролтын утгын hidden state, cell-ын state ыг буцаадаг\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# lstm - с гарсан hidden state ын хэлбэрийг өөрчилж, fc - д өгсөнөөр тухайн batch - ыг таамгууд гарна.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinearDP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# batch ын prediction - ууд. shape = batch_size * max(input_lengths)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0;32m--> 665\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    666\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7G8wl_YklWI"
      },
      "source": [
        "set(\"hhe he hheee lol lol lol\".split())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}